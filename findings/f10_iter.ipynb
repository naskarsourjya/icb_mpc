{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings 5\n",
    "Dated: 30.06.2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Get the notebook's current directory\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "# Move one level up to get the parent directory\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from module import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# computation device\n",
    "This variable sets the device to be used for the Neural Network trainings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computation_device = 'auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_results(results_dicts):\n",
    "    filename = 'results_no_plot.csv'\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(filename)\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "    # check if df is empty, assign a new column name 'Serial No.' and add it to all dicts\n",
    "    if df.empty:\n",
    "        for i, result_dict in enumerate(results_dicts, start=1):\n",
    "            result_dict['Serial No.'] = i\n",
    "\n",
    "    # df is not empty, assign the next serial number\n",
    "    else:\n",
    "        last_serial_no = df['Serial No.'].max()\n",
    "        for result_dict in results_dicts:\n",
    "            last_serial_no += 1\n",
    "            result_dict['Serial No.'] = last_serial_no\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    new_df = pd.DataFrame(results_dicts)\n",
    "\n",
    "    # put the 'Serial No.' as the first column\n",
    "    new_df = new_df[['Serial No.'] + [col for col in new_df.columns if col != 'Serial No.']]\n",
    "\n",
    "    # Append the new DataFrame to the existing one\n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "    # Save the updated DataFrame to the CSV file\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# system init\n",
    "This is a generic spring damper setup. Very simple and linear, with two states and one input. The state euation is the force balance of a spring damper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cstr_system = CSTR_dompc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spring_system.lbu = np.array([-10])       # [lower_bound_f_ext]\n",
    "#spring_system.ubu = np.array([10])        # [upper_bound_f_ext]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# surrogate generator init\n",
    "This class is designed to be totally generic, i.e., it can take any do-mpc model, or at least that is the idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DataManager(set_seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random data\n",
    "\n",
    "Here we generate sampled with one random initial point and random inputs. Then the data and the data is split randomly to feed different parts of the algorithm.\n",
    "There is another alternate algorithm which generates data by chasing random setpoints with the help of an MPC controller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.random_input_sampler(system = cstr_system, n_samples=2000)\n",
    "dm.data_splitter(order=1, narx_train= 0.3, cqr_train= 0.3, cqr_calibration= 0.3, test = 0.1)\n",
    "#dm.data_splitter(order=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.visualize_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NARX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.train_narx(hidden_layers=[5], batch_size=1000,\n",
    "          learning_rate=0.1, epochs= 1000, scheduler_flag=True, device=computation_device, train_threshold=None)\n",
    "dm.narx.plot_narx_training_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conformal quantile regression\n",
    "Here qunatile regression is done to bound the errors with confidence values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.train_cqr(alpha=0.05, hidden_layers=[20],  epochs= 1000, batch_size=1000, \n",
    "             device=computation_device, train_threshold=None)\n",
    "dm.cqr.plot_qr_training_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section visualises the quantile regression on the calibration data which the regressors has yet not seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.cqr_plot_qr_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is made against test data which till now is untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.plot_cqr_error_plotly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# verifying simulator performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking simulator performance\n",
    "C_a0 = 0.8 # This is the initial concentration inside the tank [mol/l]\n",
    "C_b0 = 0.5 # This is the controlled variable [mol/l]\n",
    "T_R0 = 134.14 #[C]\n",
    "T_K0 = 130.0 #[C]\n",
    "\n",
    "#C_a0 = 0\n",
    "#C_b0 = 0\n",
    "#T_R0 = 387.05\n",
    "#T_J0 = 387.05\n",
    "\n",
    "x_init = np.random.uniform(cstr_system.lbx, cstr_system.ubx).reshape((1, -1))\n",
    "dm.check_simulator(system=cstr_system, iter= 50, x_init=x_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iterative case study report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 50\n",
    "setpoint = None\n",
    "counter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lqr_r_list = [100, 200]\n",
    "lqr_q_list = [1]\n",
    "tightner_list = [1,1.3]\n",
    "confidence_cutoff_list = [0.9, 0.85, 0.8]\n",
    "rnd_samples_list = [7, 3, 1]\n",
    "max_search_list = [5, 10]\n",
    "r_horizon_list = [3, 5]\n",
    "n_horizon_list = [10, 15, 20]\n",
    "r_list = [0.01, 0.05, 0.1]\n",
    "\n",
    "permutations = product(lqr_r_list, lqr_q_list, tightner_list, \n",
    "                       confidence_cutoff_list, rnd_samples_list, max_search_list, \n",
    "                       r_horizon_list, n_horizon_list, r_list)\n",
    "\n",
    "n_possible_cases = len(lqr_r_list) * len(lqr_q_list) * len(tightner_list) * \\\n",
    "                    len(confidence_cutoff_list) * len(rnd_samples_list) * \\\n",
    "                    len(max_search_list) * len(r_horizon_list) * \\\n",
    "                    len(n_horizon_list) * len(r_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lqr_r, lqr_q, tightner, confidence_cutoff, rnd_samples, max_search, r_horizon, n_horizon, r in permutations:\n",
    "\n",
    "    # init\n",
    "    results_dicts = []\n",
    "    R = lqr_r * np.array([[1 / (95 * 95), 0],\n",
    "                          [0, 1 / (8500 * 8500)]])\n",
    "    Q = lqr_q * np.array([[1 / (1.9 * 1.9), 0, 0, 0],\n",
    "                          [0, 1 / (1.9 * 1.9), 0, 0],\n",
    "                          [0, 0, 1 / (90 * 90), 0],\n",
    "                          [0, 0, 0, 1 / (90 * 90)]])\n",
    "    x_init = np.random.uniform(cstr_system.lbx, cstr_system.ubx).reshape((1, -1))\n",
    "\n",
    "    # case study 1\n",
    "    print(f\"Running case study 1 : {counter}/{n_possible_cases} ---->>>\")\n",
    "    cs1 = dm.case_study_1(system=cstr_system, iter=iter, setpoint=setpoint,\n",
    "                          n_horizon=n_horizon, r=r,\n",
    "                          tightner=tightner, confidence_cutoff=confidence_cutoff,\n",
    "                          rnd_samples=rnd_samples, max_search=max_search, R=R, Q=Q,\n",
    "                          x_init=x_init, store_gif=False)\n",
    "    cs1['LQR r'] = lqr_r\n",
    "    cs1['LQR q'] = lqr_q\n",
    "    results_dicts.append(cs1)\n",
    "\n",
    "    # clear output\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # case study 2\n",
    "    print(f\"Running case study 2 : {counter}/{n_possible_cases} ---->>>\")\n",
    "    dm.setup_case_study_2(hidden_layers=[10, 10], system=cstr_system, setpoint=setpoint,\n",
    "                          n_horizon=n_horizon, r=r, epochs=1000, batch_size=1000)\n",
    "    cs2 = dm.case_study_2(system=cstr_system, iter=iter, x_init=x_init)\n",
    "    results_dicts.append(cs2)\n",
    "\n",
    "    # clear output\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # case study 3\n",
    "    print(f\"Running case study 3 : {counter}/{n_possible_cases} ---->>>\")\n",
    "    dm.setup_case_study_3(system=cstr_system, n_horizon=n_horizon, r_horizon=r_horizon, r=r, setpoint=setpoint)\n",
    "    cs3 = dm.case_study_3(system=cstr_system, iter=iter, x_init=x_init)\n",
    "    cs3['MPC Robust Horizon'] = r_horizon\n",
    "    results_dicts.append(cs3)\n",
    "\n",
    "    # clear output\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # case study 4\n",
    "    print(f\"Running case study 4 : {counter}/{n_possible_cases} ---->>>\")\n",
    "    dm.setup_case_study_4(system=cstr_system, n_horizon=n_horizon, r=r, setpoint=setpoint)\n",
    "    cs4 = dm.case_study_4(system=cstr_system, iter=iter, x_init=x_init)\n",
    "    results_dicts.append(cs4)\n",
    "\n",
    "    # clear output\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # case study 5\n",
    "    print(f\"Running case study 5 : {counter}/{n_possible_cases} ---->>>\")\n",
    "    cs5 = dm.case_study_5(system=cstr_system, iter=iter, setpoint=setpoint,\n",
    "                          n_horizon=n_horizon, r=r,\n",
    "                          tightner=tightner, confidence_cutoff=confidence_cutoff, rnd_samples=rnd_samples,\n",
    "                          max_search=max_search,\n",
    "                          x_init=x_init, store_gif=False)\n",
    "    results_dicts.append(cs5)\n",
    "\n",
    "    # clear output\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # result storage\n",
    "    _save_results(results_dicts)\n",
    "\n",
    "    # counter update\n",
    "    counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cqr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
